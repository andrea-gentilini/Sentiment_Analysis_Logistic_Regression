{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9bCFfo9SQI5"
      },
      "outputs": [],
      "source": [
        "# importing modules\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/pieroit/corso_ml_python_youtube_pollo/master/movie_review.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "im7GaMyGSTI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "X = df['text']\n",
        "\n",
        "def clean_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    pronouns = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves'}\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove all special characters\n",
        "    processed_text = re.sub(r'\\W', ' ', text)\n",
        "\n",
        "    # Remove all single characters\n",
        "    processed_text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_text)\n",
        "\n",
        "    # Remove single characters from the start\n",
        "    processed_text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_text)\n",
        "\n",
        "    # Substituting multiple spaces with single space\n",
        "    processed_text = re.sub(r'\\s+', ' ', processed_text, flags=re.I)\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(processed_text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [word for word in words if word not in stop_words and word not in pronouns]\n",
        "\n",
        "    # Join the words back to a string\n",
        "    processed_text = ' '.join(words)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "processed_texts = [clean_text(text) for text in X]"
      ],
      "metadata": {
        "id": "okzq7WrCSU9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = processed_texts\n",
        "y = df['tag']"
      ],
      "metadata": {
        "id": "jAmgtAjlSg4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X).toarray()"
      ],
      "metadata": {
        "id": "qa9bqzGhSjJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
      ],
      "metadata": {
        "id": "ZsIxynceSl1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with scikit-learn\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Vm18Q-ZUSn1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "p_train = model.predict(X_train)\n",
        "p_test = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracies\n",
        "acc_train = accuracy_score(y_train, p_train)\n",
        "acc_test = accuracy_score(y_test, p_test)\n",
        "\n",
        "# Print results\n",
        "print(f'Training accuracy: {acc_train}, Test accuracy: {acc_test}')"
      ],
      "metadata": {
        "id": "3iBHPNW9StmM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}